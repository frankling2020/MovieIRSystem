{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haoyang/miniconda3/envs/si650/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"wikipedia_200k_dataset.jsonl.gz\"\n",
    "TRAIN_DATA_PATH = \"hw3_relevance.train.csv\"\n",
    "DEV_DATA_PATH = \"hw3_relevance.dev.csv\"\n",
    "TEST_DATA_PATH = \"hw3_relevance.test.csv\"\n",
    "NETWORK_STATS_PATH = 'network_stats.csv'\n",
    "INDEX_PATH = \"./main_index\"\n",
    "DOC_CATEGORY_INFO_PATH = 'doc_category_info.json'\n",
    "RECOGNIZED_CATEGORY_PATH = 'recognized_categories.txt'\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset and Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(dataset_path: str, max_docs: int = -1):\n",
    "    open_func = lambda x: gzip.open(x, 'rb') if x.endswith('.gz') else open(x, 'r')\n",
    "    with open_func(dataset_path) as f:\n",
    "        for i, line in tqdm(enumerate(f)):\n",
    "            if max_docs != -1 and i >= max_docs:\n",
    "                break\n",
    "            x = json.loads(line)\n",
    "            # x[\"docid\"] = str(x[\"docid\"])\n",
    "            x[\"docno\"] = str(x[\"docid\"])\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf main_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_index_path = INDEX_PATH\n",
    "\n",
    "docids = set()\n",
    "if not os.path.exists(pt_index_path + \"/data.properties\"):\n",
    "    # create the index, using the IterDictIndexer indexer \n",
    "    indexer = pt.index.IterDictIndexer(pt_index_path, tokenizer=tokenizer, blocks=True, verbose=True)\n",
    "    NUM_DOCS = -1\n",
    "    doc_iter = read_dataset(DATASET_PATH, NUM_DOCS)\n",
    "    doc_iter = read_dataset(DATASET_PATH, NUM_DOCS)\n",
    "    index_ref = indexer.index(doc_iter, fields=['text'], meta=['docno', 'title'])\n",
    "else:\n",
    "    # if you already have the index, use it.\n",
    "    index_ref = pt.IndexRef.of(pt_index_path + \"/data.properties\")\n",
    "\n",
    "index = pt.IndexFactory.of(index_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path, qcol):\n",
    "    df = pd.read_csv(dataset_path).dropna()\n",
    "    queries = df[qcol].astype(str).unique()\n",
    "    query_to_id = {q: str(i) for i, q in enumerate(queries)}\n",
    "    df[\"qid\"] = df[qcol].apply(lambda x: query_to_id[x])\n",
    "    df[\"docno\"] = df[\"docid\"].apply(lambda x: str(x))\n",
    "    df[\"label\"] = df[\"rel\"]\n",
    "    topics = df[[qcol, \"qid\"]].copy().drop_duplicates()\n",
    "    topics.columns = [\"query\", \"qid\"]\n",
    "    topics = topics.astype({\"qid\": str})\n",
    "    topics[\"query\"] = topics[\"query\"].apply(lambda x: re.sub(r\"'\", \" \", x))\n",
    "    qrels = df[[\"qid\", \"docno\", \"label\"]].copy()\n",
    "    return topics, qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_topics, train_qrels = load_data(TRAIN_DATA_PATH, \"query\")\n",
    "validation_topics, validation_qrels = load_data(DEV_DATA_PATH, \"query\")\n",
    "test_topics, test_qrels = load_data(TEST_DATA_PATH, \"query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_my_feat(keyFreq, postings, entryStats, collStats):\n",
    "    return postings.getFrequency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pivoted_normalization_weighting(keyFreq, posting, entryStats, collStats):\n",
    "#     b1 = 0.2\n",
    "#     num_doc = collStats.numberOfDocuments\n",
    "#     num_token = collStats.numberOfTokens\n",
    "#     avdl = num_token/num_doc\n",
    "\n",
    "#     doc_len = posting.getDocumentLength()\n",
    "#     num_terms_in_doc = posting.getFrequency()\n",
    "#     df_t = entryStats.getDocumentFrequency()\n",
    "\n",
    "#     qtf = keyFreq\n",
    "#     tf_no = 1 + math.log(1 + math.log(num_terms_in_doc))\n",
    "#     tf = tf_no/(1-b1+b1*doc_len/avdl)\n",
    "#     idf = math.log((num_doc+1)/df_t)\n",
    "\n",
    "#     score = idf*tf*qtf\n",
    "#     return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_toks = pt.rewrite.tokenise(tokeniser=lambda x: tokenizer.tokenize(x), matchop=True)\n",
    "bm25 = query_toks >> pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "get_title = pt.text.get_text(index, 'title')\n",
    "tf_title = pt.text.scorer(body_attr=\"title\", wmodel=fetch_my_feat)\n",
    "tf_text = pt.BatchRetrieve(index, wmodel=fetch_my_feat)\n",
    "tf_idf_title = query_toks >> pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n",
    "tf_idf_text = query_toks >> pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n",
    "pivoted_doc =  query_toks >> pt.BatchRetrieve(index, wmodel=pivoted_normalization_weighting)\n",
    "pl2 = query_toks >> pt.BatchRetrieve(index, wmodel=\"PL2\")\n",
    "dlm = query_toks >> pt.BatchRetrieve(index, wmodel=\"DirichletLM\")\n",
    "sdm = pt.rewrite.SDM()\n",
    "qe = pt.rewrite.Bo1QueryExpansion(index)\n",
    "cm = query_toks >> pt.BatchRetrieve(index, wmodel=\"CoordinateMatch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pt.Experiment:   0%|          | 0/6 [00:00<?, ?system/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pt.Experiment: 100%|██████████| 6/6 [00:46<00:00,  7.70s/system]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.071624</td>\n",
       "      <td>0.186296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TF_IDF_Title</td>\n",
       "      <td>0.079237</td>\n",
       "      <td>0.198254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TF_IDF_Text</td>\n",
       "      <td>0.079237</td>\n",
       "      <td>0.198254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PL2</td>\n",
       "      <td>0.052178</td>\n",
       "      <td>0.176700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DLM</td>\n",
       "      <td>0.079928</td>\n",
       "      <td>0.227606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CM</td>\n",
       "      <td>0.147529</td>\n",
       "      <td>0.144782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name       map  ndcg_cut_10\n",
       "0          BM25  0.071624     0.186296\n",
       "1  TF_IDF_Title  0.079237     0.198254\n",
       "2   TF_IDF_Text  0.079237     0.198254\n",
       "3           PL2  0.052178     0.176700\n",
       "4           DLM  0.079928     0.227606\n",
       "5            CM  0.147529     0.144782"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier.measures import *\n",
    "pt.Experiment(\n",
    "    [\n",
    "        bm25,\n",
    "        tf_idf_title,\n",
    "        tf_idf_text,\n",
    "        pl2,\n",
    "        dlm,\n",
    "        cm\n",
    "    ],\n",
    "    train_topics,\n",
    "    train_qrels,\n",
    "    filter_by_qrels=True,\n",
    "    eval_metrics=[\"map\", \"ndcg_cut_10\"],\n",
    "    verbose=True,\n",
    "    names=[\"BM25\", \"TF_IDF_Title\", \"TF_IDF_Text\", \"PL2\", \"DLM\", \"CM\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.Experiment(\n",
    "    [\n",
    "        bm25,\n",
    "        tf_idf_title,\n",
    "        tf_idf_text,\n",
    "        pl2,\n",
    "        dlm,\n",
    "        cm\n",
    "    ],\n",
    "    test_topics,\n",
    "    test_qrels,\n",
    "    filter_by_qrels=True,\n",
    "    eval_metrics=[\"map\", \"ndcg_cut_10\"],\n",
    "    verbose=True,\n",
    "    names=[\"BM25\", \"TF_IDF_Title\", \"TF_IDF_Text\", \"PL2\", \"DLM\", \"CM\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learn-to-Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999841it [00:21, 46036.28it/s]\n"
     ]
    }
   ],
   "source": [
    "ENCODED_DOCUMENT_EMBEDDINGS_NPY_DATA = 'wiki-200k-vecs.msmarco-MiniLM-L12-cos-v5.npy'\n",
    "DOCUMENT_ID_TEXT = 'document-ids.txt'\n",
    "\n",
    "encoded_docs = None\n",
    "with open(ENCODED_DOCUMENT_EMBEDDINGS_NPY_DATA, 'rb') as file:\n",
    "    encoded_docs = np.load(file)\n",
    "\n",
    "document_ids = None\n",
    "with open(DOCUMENT_ID_TEXT, 'r') as f:\n",
    "    document_ids = f.read().splitlines()\n",
    "document_ids = [int(x) for x in document_ids]\n",
    "\n",
    "recognized_categories = None\n",
    "with open(RECOGNIZED_CATEGORY_PATH, 'r') as f:\n",
    "    recognized_categories = f.read().splitlines()\n",
    "\n",
    "doc_category_info = None\n",
    "with open(DOC_CATEGORY_INFO_PATH, 'r') as f:\n",
    "    doc_category_info = json.load(f)\n",
    "\n",
    "doc_category_info = None\n",
    "with open(DOC_CATEGORY_INFO_PATH, 'r') as f:\n",
    "    doc_category_info = json.load(f)\n",
    "\n",
    "network_features = {}\n",
    "networks_stats = pd.read_csv(NETWORK_STATS_PATH, index_col=0)\n",
    "for row in tqdm(networks_stats.iterrows()):\n",
    "    network_features[row[1]['docid']] = row[1][1:].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, model_name, index, document_ids, encoded_docs, \n",
    "            network_features, doc_category_info, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.index = index\n",
    "        self.doc_ids = document_ids\n",
    "        self.encoded_docs = encoded_docs\n",
    "        self.encoder = SentenceTransformer(model_name)\n",
    "        self.query_emb = {}\n",
    "        self.network_features = network_features\n",
    "        self.doc_category_info = doc_category_info\n",
    "        self.category_to_id = {k: v for v, k in enumerate(recognized_categories)}\n",
    "\n",
    "    def get_document_categories(self, docid):\n",
    "        doc_categories = [0 for _ in range(len(self.category_to_id))]\n",
    "        for category in self.doc_category_info[str(docid)]:\n",
    "            if category in self.category_to_id:\n",
    "                doc_categories[self.category_to_id[category]] = 1\n",
    "        return doc_categories\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def add_features(self, row):\n",
    "        docid = int(row[\"docid\"])\n",
    "        docno = int(row[\"docno\"])\n",
    "        content = row[\"query\"]\n",
    "        qid = row[\"qid\"]\n",
    "        f1 = len(tokenizer.tokenize(content))\n",
    "        query_emb = None\n",
    "        if qid not in self.query_emb:\n",
    "            query_emb = self.encoder.encode(content, normalize_embeddings=True)\n",
    "            self.query_emb[qid] = query_emb\n",
    "        else:\n",
    "            query_emb = self.query_emb[qid]\n",
    "        doc_emb = self.encoded_docs[document_ids.index(docno)]\n",
    "        f2 = util.dot_score(query_emb, doc_emb).item()\n",
    "        content = row[\"title\"]\n",
    "        f3 = len(tokenizer.tokenize(content))\n",
    "        f4 = index.getDocumentIndex().getDocumentLength(docid)\n",
    "        return np.array([f1, f2, f3, f4, *self.network_features[docno].values(), *self.get_document_categories(docno)])\n",
    "\n",
    "fe = FeatureExtractor('sentence-transformers/msmarco-MiniLM-L12-cos-v5', \n",
    "            index, document_ids, encoded_docs, network_features, doc_category_info, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query_0</th>\n",
       "      <th>query</th>\n",
       "      <th>title</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>54874</td>\n",
       "      <td>21022536</td>\n",
       "      <td>0</td>\n",
       "      <td>12.024897</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>Golden Retriever</td>\n",
       "      <td>[2.0, 0.1951461136341095, 2.0, 1101.0, 2.00231...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>199272</td>\n",
       "      <td>375096</td>\n",
       "      <td>1</td>\n",
       "      <td>12.017616</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>[2.0, 0.24166104197502136, 1.0, 148.0, 1.66391...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>188673</td>\n",
       "      <td>537218</td>\n",
       "      <td>2</td>\n",
       "      <td>11.959106</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>Gun dog</td>\n",
       "      <td>[2.0, 0.0508037805557251, 2.0, 506.0, 2.228500...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>29258</td>\n",
       "      <td>79280</td>\n",
       "      <td>3</td>\n",
       "      <td>11.778672</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>Labrador Retriever</td>\n",
       "      <td>[2.0, 0.15273529291152954, 2.0, 760.0, 2.57849...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>91010</td>\n",
       "      <td>4743980</td>\n",
       "      <td>4</td>\n",
       "      <td>11.693882</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>Tip of the tongue</td>\n",
       "      <td>[2.0, 0.3024318814277649, 4.0, 2116.0, 1.75525...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>128064</td>\n",
       "      <td>1717129</td>\n",
       "      <td>95</td>\n",
       "      <td>10.094906</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>Explicit memory</td>\n",
       "      <td>[2.0, 0.13990920782089233, 2.0, 2916.0, 1.4674...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>29259</td>\n",
       "      <td>79289</td>\n",
       "      <td>96</td>\n",
       "      <td>10.051436</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>German Shepherd</td>\n",
       "      <td>[2.0, -0.051451295614242554, 2.0, 2376.0, 2.60...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>53148</td>\n",
       "      <td>24799509</td>\n",
       "      <td>97</td>\n",
       "      <td>10.048728</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>Graph database</td>\n",
       "      <td>[2.0, 0.24931509792804718, 2.0, 1759.0, 4.9765...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>152617</td>\n",
       "      <td>933503</td>\n",
       "      <td>98</td>\n",
       "      <td>10.031661</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>Nanobe</td>\n",
       "      <td>[2.0, -0.007376858964562416, 1.0, 212.0, 3.438...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>111080</td>\n",
       "      <td>2351677</td>\n",
       "      <td>99</td>\n",
       "      <td>10.027288</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>News aggregator</td>\n",
       "      <td>[2.0, 0.297031044960022, 2.0, 1156.0, 8.341702...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid   docid     docno  rank      score                query_0  \\\n",
       "0    1   54874  21022536     0  12.024897  information retrieval   \n",
       "1    1  199272    375096     1  12.017616  information retrieval   \n",
       "2    1  188673    537218     2  11.959106  information retrieval   \n",
       "3    1   29258     79280     3  11.778672  information retrieval   \n",
       "4    1   91010   4743980     4  11.693882  information retrieval   \n",
       "..  ..     ...       ...   ...        ...                    ...   \n",
       "95   1  128064   1717129    95  10.094906  information retrieval   \n",
       "96   1   29259     79289    96  10.051436  information retrieval   \n",
       "97   1   53148  24799509    97  10.048728  information retrieval   \n",
       "98   1  152617    933503    98  10.031661  information retrieval   \n",
       "99   1  111080   2351677    99  10.027288  information retrieval   \n",
       "\n",
       "                    query               title  \\\n",
       "0   information retrieval    Golden Retriever   \n",
       "1   information retrieval           Retriever   \n",
       "2   information retrieval             Gun dog   \n",
       "3   information retrieval  Labrador Retriever   \n",
       "4   information retrieval   Tip of the tongue   \n",
       "..                    ...                 ...   \n",
       "95  information retrieval     Explicit memory   \n",
       "96  information retrieval     German Shepherd   \n",
       "97  information retrieval      Graph database   \n",
       "98  information retrieval              Nanobe   \n",
       "99  information retrieval     News aggregator   \n",
       "\n",
       "                                             features  \n",
       "0   [2.0, 0.1951461136341095, 2.0, 1101.0, 2.00231...  \n",
       "1   [2.0, 0.24166104197502136, 1.0, 148.0, 1.66391...  \n",
       "2   [2.0, 0.0508037805557251, 2.0, 506.0, 2.228500...  \n",
       "3   [2.0, 0.15273529291152954, 2.0, 760.0, 2.57849...  \n",
       "4   [2.0, 0.3024318814277649, 4.0, 2116.0, 1.75525...  \n",
       "..                                                ...  \n",
       "95  [2.0, 0.13990920782089233, 2.0, 2916.0, 1.4674...  \n",
       "96  [2.0, -0.051451295614242554, 2.0, 2376.0, 2.60...  \n",
       "97  [2.0, 0.24931509792804718, 2.0, 1759.0, 4.9765...  \n",
       "98  [2.0, -0.007376858964562416, 1.0, 212.0, 3.438...  \n",
       "99  [2.0, 0.297031044960022, 2.0, 1156.0, 8.341702...  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = (bm25 % 100) >> get_title >>  pt.apply.doc_features(fe.add_features)\n",
    "pipeline.search(\"information retrieval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANK_CUTOFF = 100\n",
    "pipeline = (bm25 % RANK_CUTOFF) >> get_title >> (\n",
    "    # \n",
    "    pt.apply.doc_features(fe.add_features)\n",
    "    **\n",
    "    # BM25\n",
    "    bm25\n",
    "    **\n",
    "    # TF_TITLE\n",
    "    tf_title \n",
    "    ** \n",
    "    # TF_DOC\n",
    "    tf_text\n",
    "    ** \n",
    "    # TF_IDF_TITLE\n",
    "    tf_idf_title\n",
    "    **\n",
    "    # TF_IDF_DOC\n",
    "    tf_idf_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:57:42.046 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
      "15:58:00.977 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haoyang/miniconda3/envs/si650/lib/python3.11/site-packages/lightgbm/sklearn.py:682: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2552\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pt.Experiment:  50%|█████     | 1/2 [00:01<00:01,  1.98s/system]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:58:10.299 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haoyang/miniconda3/envs/si650/lib/python3.11/site-packages/lightgbm/sklearn.py:682: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "pt.Experiment: 100%|██████████| 2/2 [00:11<00:00,  5.59s/system]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25 Baseline</td>\n",
       "      <td>0.061286</td>\n",
       "      <td>0.148466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LambdaMART (LightGBM)</td>\n",
       "      <td>0.051781</td>\n",
       "      <td>0.238501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name       map  ndcg_cut_10\n",
       "0          BM25 Baseline  0.061286     0.148466\n",
       "1  LambdaMART (LightGBM)  0.051781     0.238501"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "# this configures LightGBM as LambdaMART\n",
    "\n",
    "default_params = {\n",
    "    'objective': \"lambdarank\",\n",
    "    'boosting_type': \"gbdt\",\n",
    "    'n_estimators': 20,\n",
    "    'importance_type': \"gain\",\n",
    "    'metric': \"ndcg\",\n",
    "    'eval_at': [10],\n",
    "    'num_leaves': 20,\n",
    "    'learning_rate': 0.005,\n",
    "    'max_depth': -1,\n",
    "    \"verbosity\": 1,\n",
    "}\n",
    "\n",
    "\n",
    "lmart_l = lgb.LGBMRanker(**default_params)\n",
    "lmart_l_pipe = pipeline >> pt.ltr.apply_learned_model(lmart_l, form=\"ltr\")\n",
    "lmart_l_pipe.fit(train_topics, train_qrels, validation_topics, validation_qrels)\n",
    "\n",
    "pt.Experiment(\n",
    "    [bm25, lmart_l_pipe],\n",
    "    test_topics,\n",
    "    test_qrels,\n",
    "    [\"map\", \"ndcg_cut_10\"],\n",
    "    names=[\"BM25 Baseline\", \"LambdaMART (LightGBM)\" ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x2c5461990>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmart_l.booster_.save_model(\"lmart_l.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(self, file_name: str = 'l2r.model.txt') -> None:\n",
    "        self.model.booster_.save_model(file_name)\n",
    "    \n",
    "    def load(self, file_name: str = 'l2r.model.txt') -> None:\n",
    "        self.model = lightgbm.Booster(model_file=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:58:46.392 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haoyang/miniconda3/envs/si650/lib/python3.11/site-packages/lightgbm/sklearn.py:682: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25 Baseline</td>\n",
       "      <td>0.067452</td>\n",
       "      <td>0.196534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LambdaMART (LightGBM)</td>\n",
       "      <td>0.050117</td>\n",
       "      <td>0.261852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name       map  ndcg_cut_10\n",
       "0          BM25 Baseline  0.067452     0.196534\n",
       "1  LambdaMART (LightGBM)  0.050117     0.261852"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [bm25, lmart_l_pipe],\n",
    "    validation_topics,\n",
    "    validation_qrels,\n",
    "    [\"map\", \"ndcg_cut_10\"],\n",
    "    names=[\"BM25 Baseline\", \"LambdaMART (LightGBM)\" ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:10:01.202 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haoyang/miniconda3/envs/si650/lib/python3.11/site-packages/lightgbm/sklearn.py:682: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>score</th>\n",
       "      <th>query_0</th>\n",
       "      <th>query</th>\n",
       "      <th>title</th>\n",
       "      <th>features</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1</td>\n",
       "      <td>39586</td>\n",
       "      <td>31217535</td>\n",
       "      <td>0.046718</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>Memory</td>\n",
       "      <td>[2.0, 0.3415633738040924, 1.0, 4833.0, 1.36696...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>21734</td>\n",
       "      <td>149354</td>\n",
       "      <td>0.029184</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>Information science</td>\n",
       "      <td>[2.0, 0.35018330812454224, 2.0, 2083.0, 1.0993...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>21721</td>\n",
       "      <td>149306</td>\n",
       "      <td>-0.001016</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>National Center for Biotechnology Information</td>\n",
       "      <td>[2.0, 0.224349245429039, 5.0, 584.0, 0.0001142...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>29259</td>\n",
       "      <td>79289</td>\n",
       "      <td>-0.013296</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>German Shepherd</td>\n",
       "      <td>[2.0, -0.051451295614242554, 2.0, 2376.0, 2.60...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1</td>\n",
       "      <td>51121</td>\n",
       "      <td>21312318</td>\n",
       "      <td>-0.014123</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>Recognition memory</td>\n",
       "      <td>[2.0, 0.3847505450248718, 2.0, 3203.0, 4.33027...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "      <td>10609</td>\n",
       "      <td>38167907</td>\n",
       "      <td>-0.168926</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>Lego Marvel Super Heroes (video games)</td>\n",
       "      <td>[2.0, 0.10809655487537384, 6.0, 1044.0, 5.3187...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "      <td>94077</td>\n",
       "      <td>4700242</td>\n",
       "      <td>-0.168926</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>Mars sample-return mission</td>\n",
       "      <td>[2.0, 0.32669755816459656, 4.0, 1051.0, 1.9449...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "      <td>69739</td>\n",
       "      <td>14559427</td>\n",
       "      <td>-0.168926</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>File URI scheme</td>\n",
       "      <td>[2.0, 0.14401458203792572, 3.0, 478.0, 1.74983...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1</td>\n",
       "      <td>187965</td>\n",
       "      <td>898293</td>\n",
       "      <td>-0.168926</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>Force play</td>\n",
       "      <td>[2.0, -0.10385392606258392, 2.0, 493.0, 2.5194...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>152617</td>\n",
       "      <td>933503</td>\n",
       "      <td>-0.168926</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>Nanobe</td>\n",
       "      <td>[2.0, -0.007376858964562416, 1.0, 212.0, 3.438...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid   docid     docno     score                query_0  \\\n",
       "86   1   39586  31217535  0.046718  information retrieval   \n",
       "43   1   21734    149354  0.029184  information retrieval   \n",
       "49   1   21721    149306 -0.001016  information retrieval   \n",
       "96   1   29259     79289 -0.013296  information retrieval   \n",
       "65   1   51121  21312318 -0.014123  information retrieval   \n",
       "..  ..     ...       ...       ...                    ...   \n",
       "88   1   10609  38167907 -0.168926  information retrieval   \n",
       "89   1   94077   4700242 -0.168926  information retrieval   \n",
       "91   1   69739  14559427 -0.168926  information retrieval   \n",
       "93   1  187965    898293 -0.168926  information retrieval   \n",
       "98   1  152617    933503 -0.168926  information retrieval   \n",
       "\n",
       "                    query                                          title  \\\n",
       "86  information retrieval                                         Memory   \n",
       "43  information retrieval                            Information science   \n",
       "49  information retrieval  National Center for Biotechnology Information   \n",
       "96  information retrieval                                German Shepherd   \n",
       "65  information retrieval                             Recognition memory   \n",
       "..                    ...                                            ...   \n",
       "88  information retrieval         Lego Marvel Super Heroes (video games)   \n",
       "89  information retrieval                     Mars sample-return mission   \n",
       "91  information retrieval                                File URI scheme   \n",
       "93  information retrieval                                     Force play   \n",
       "98  information retrieval                                         Nanobe   \n",
       "\n",
       "                                             features  rank  \n",
       "86  [2.0, 0.3415633738040924, 1.0, 4833.0, 1.36696...     0  \n",
       "43  [2.0, 0.35018330812454224, 2.0, 2083.0, 1.0993...     1  \n",
       "49  [2.0, 0.224349245429039, 5.0, 584.0, 0.0001142...     2  \n",
       "96  [2.0, -0.051451295614242554, 2.0, 2376.0, 2.60...     3  \n",
       "65  [2.0, 0.3847505450248718, 2.0, 3203.0, 4.33027...     4  \n",
       "..                                                ...   ...  \n",
       "88  [2.0, 0.10809655487537384, 6.0, 1044.0, 5.3187...    95  \n",
       "89  [2.0, 0.32669755816459656, 4.0, 1051.0, 1.9449...    96  \n",
       "91  [2.0, 0.14401458203792572, 3.0, 478.0, 1.74983...    97  \n",
       "93  [2.0, -0.10385392606258392, 2.0, 493.0, 2.5194...    98  \n",
       "98  [2.0, -0.007376858964562416, 1.0, 212.0, 3.438...    99  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmart_l_pipe.search(\"information retrieval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bi-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bimodel = SentenceTransformer('sentence-transformers/msmarco-MiniLM-L12-cos-v5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _biencoder_apply(df : pd.DataFrame):\n",
    "    query_embs = bimodel.encode(df['query'].values)\n",
    "    # print(df['docid'].values)\n",
    "    doc_embs = bimodel.encode(df['query'].values)\n",
    "    # doc_embs = bimodel.encode(df['text'].values)\n",
    "    scores = util.dot_score(query_embs, doc_embs)\n",
    "    # print(query_embs.shape, doc_embs.shape, scores.shape)\n",
    "    return scores[0]\n",
    "\n",
    "bi_encT = pt.apply.doc_score(_biencoder_apply, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.Experiment(\n",
    "    [ bm25, query_toks >>  pt.BatchRetrieve(index) >> bi_encT],\n",
    "    train_topics,\n",
    "    train_qrels,\n",
    "    [\"map\", \"ndcg_cut_10\"],\n",
    "    names=[\"BM25\", \"BM25 >> BiEncoder\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pt.apply: 100%|██████████| 1/1 [00:00<00:00, 28.77row/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>score</th>\n",
       "      <th>query_0</th>\n",
       "      <th>query</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>54301172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>52231341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>information retrieval</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid  docid     docno  score                query_0                  query  \\\n",
       "0   1      8  54301172    1.0  information retrieval  information retrieval   \n",
       "1   1      3  52231341    1.0  information retrieval  information retrieval   \n",
       "\n",
       "   rank  \n",
       "0     0  \n",
       "1     1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = query_toks >> pt.BatchRetrieve(index) >> bi_encT\n",
    "pipeline.search(\"information retrieval\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si650",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
