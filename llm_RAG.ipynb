{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"results/results_12_2_query.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "test_qids = [8, 15, 29, 39, 43]\n",
    "df_selected = df[df[\"qid\"].isin(test_qids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = {}\n",
    "for qid in test_qids:\n",
    "    a = df_selected[(df_selected[\"qid\"] == qid) & (df_selected[\"model\"] == \"pipeline_6\")]\n",
    "    ranker[qid] = a.title.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pipeline_0', 'pipeline_1', 'pipeline_2', 'pipeline_3',\n",
       "       'pipeline_4', 'pipeline_5', 'pipeline_6'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selected.model.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>data</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The movie Toy Story (1995) belongs to the foll...</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The movie Jumanji (1995) belongs to the follow...</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The movie Grumpier Old Men (1995) belongs to t...</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The movie Waiting to Exhale (1995) belongs to ...</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The movie Father of the Bride Part II (1995) b...</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               data  \\\n",
       "0   1  The movie Toy Story (1995) belongs to the foll...   \n",
       "1   2  The movie Jumanji (1995) belongs to the follow...   \n",
       "2   3  The movie Grumpier Old Men (1995) belongs to t...   \n",
       "3   4  The movie Waiting to Exhale (1995) belongs to ...   \n",
       "4   5  The movie Father of the Bride Part II (1995) b...   \n",
       "\n",
       "                                title  \n",
       "0                    Toy Story (1995)  \n",
       "1                      Jumanji (1995)  \n",
       "2             Grumpier Old Men (1995)  \n",
       "3            Waiting to Exhale (1995)  \n",
       "4  Father of the Bride Part II (1995)  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df = pd.read_csv(\"data/movie_df.csv\", sep=\"\\t\")\n",
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"I will provide you with {num} movies, each indicated by a numerical identifier [].\n",
    "Rank the movies based on their relevance to the search query: {query}. Here are the movies that you need to rank:\n",
    "{movie_infos}\n",
    "Please rank the {num} movies above based on their relevance to the search query. \n",
    "All the movies should be included and listed using identifiers, in descending order of relevance. \n",
    "The output format should be [] > [] > ... > [], e.g., [4] > [2] > [3] > [1] > [5] if 5 movies are given. \n",
    "Only respond with the ranking results, do not say any word or explain the reason for the ranking and keep the answer\n",
    "as short as possible.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "\n",
    "for qid, movies in ranker.items():\n",
    "    query = df_test[df_test[\"qid\"] == qid].iloc[0][\"query\"]\n",
    "    movie_infos = \"\"\n",
    "    for i, movie in enumerate(movies):\n",
    "        movie_info = movie_df[movie_df[\"title\"] == movie].iloc[0]\n",
    "        movie_infos += f\"[{i+1}] {movie_info['title']}\\n\"\n",
    "    prompt = prompt_template.format(num=len(movies), query=query, movie_infos=movie_infos)\n",
    "    prompts.append(prompt)\n",
    "\n",
    "with open(\"prompts.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\\n\".join(prompts))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "\n",
    "# client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"not-needed\")\n",
    "\n",
    "# chat_answers = []\n",
    "# for prompt in prompts:\n",
    "#     completion = client.chat.completions.create(\n",
    "#         model=\"local-model\", # this field is currently unused\n",
    "#         messages=[\n",
    "#             {\"role\": \"system\", \"content\": \"Suppose you are a movie critic and you are asked to rank a list of movies based on their relevance to a search query.\"},\n",
    "#             {\"role\": \"user\", \"content\": prompt},\n",
    "#         ],\n",
    "#         temperature=0.7,\n",
    "#     )\n",
    "#     chat_answers.append(completion.choices[0].message.content)\n",
    "\n",
    "# with open(\"chat_answers.txt\", \"w\") as f:\n",
    "#     f.write(\"\\n\\n\\n\".join(chat_answers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gpt4_answer.txt\", \"r\") as f:\n",
    "    chat_answers = f.read().split(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "ranker1 = {}\n",
    "for qid, answer in zip(test_qids, chat_answers):\n",
    "    text = answer.split(\"\\n\")[0]\n",
    "    matches = re.findall(r\"\\[(.*?)\\]\", text)\n",
    "    new_list = []\n",
    "    for x in matches:\n",
    "        try:\n",
    "            new_list.append(ranker[qid][int(x)-1])\n",
    "        except:\n",
    "            match = [y for y in ranker[qid] if y[0] == x[:4]]\n",
    "            new_list.append(match[0] if len(match) else \"Not found\")\n",
    "            # print(x, match)\n",
    "    ranker1[qid] = [movie_df[movie_df.title == x].id.values[0] for x in new_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8: [167832, 22, 97304, 3499, 3798, 5266, 1219, 1982, 1387, 213347],\n",
       " 15: [953, 6936, 586, 317, 2423, 2804, 41573, 208939, 117887, 8607],\n",
       " 29: [27397,\n",
       "  92243,\n",
       "  141890,\n",
       "  53342,\n",
       "  91880,\n",
       "  165431,\n",
       "  54607,\n",
       "  61434,\n",
       "  158272,\n",
       "  127315],\n",
       " 39: [3916, 1954, 72641, 33660, 524, 7263, 31225, 261131, 2082, 34153],\n",
       " 43: [134130, 26124, 3981, 3354, 4942, 166526, 161592, 247150, 26398, 2662]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevence Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def map_score(search_result_relevances: list[int], cut_off=10) -> float:\n",
    "    print(search_result_relevances)\n",
    "    all_rel_doc = np.sum([1 if rel > 0 else 0 for rel in search_result_relevances])\n",
    "    correct_pos = [pos for pos in range(cut_off) if search_result_relevances[pos] > 0]\n",
    "    precision_k = [(i + 1) / (pos + 1) for i, pos in enumerate(correct_pos)]\n",
    "    return np.sum(precision_k) / 10 if len(precision_k) > 0 else 0\n",
    "\n",
    "\n",
    "def ndcg_score(search_result_relevances: list[float], \n",
    "               ideal_relevance_score_ordering: list[float], cut_off=10):\n",
    "    print(search_result_relevances)\n",
    "    actual_len = min(len(search_result_relevances), cut_off)\n",
    "    dcg = search_result_relevances[0] + np.sum([gain / np.log2(pos + 2) for pos, gain in enumerate(search_result_relevances[1:actual_len])]) if actual_len != 0 else 0\n",
    "    ideal_len = min(len(ideal_relevance_score_ordering), cut_off)\n",
    "    idcg = ideal_relevance_score_ordering[0] +np.sum([gain / np.log2(pos + 2) for pos, gain in enumerate(ideal_relevance_score_ordering[1:ideal_len])]) if ideal_len != 0 else 0\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "\n",
    "def run_relevance_tests(relevance_data_filename: str, ranker) -> dict[str, float]:\n",
    "    relevance_df = pd.read_csv(relevance_data_filename)\n",
    "    map_scores = []\n",
    "    ndcg_scores = []\n",
    "\n",
    "    for qid, relevance_doc in tqdm(relevance_df.groupby('qid')):\n",
    "        doc_to_rel = {}\n",
    "        for _, row in relevance_doc.iterrows():\n",
    "            doc_to_rel[row['docid']] = row['rel']\n",
    "        result_doc = ranker[qid]\n",
    "        result_rel = [doc_to_rel.get(result, 1) for result in result_doc]\n",
    "        ideal_rel = sorted(doc_to_rel.values(), reverse=True)\n",
    "        map_result_rel = list(map(lambda x: 1 if x > 3 else 0, result_rel))\n",
    "        map_scores.append(map_score(map_result_rel))\n",
    "        ndcg_scores.append(ndcg_score(result_rel, ideal_rel))\n",
    "    # TODO: Compute the average MAP and NDCG across all queries and return the scores. \n",
    "    map_avg_score = np.mean(map_scores)\n",
    "    ndcg_avg_score = np.mean(ndcg_scores)\n",
    "    # 3: Return the scores.\n",
    "    return {'map': map_avg_score, 'ndcg': ndcg_avg_score, 'map_scores': map_scores, 'ndcg_scores': ndcg_scores}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 1074.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 0, 0, 1, 0, 0, 0]\n",
      "[5, 4, 4, 4, 3, 3, 5, 2, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 4]\n",
      "[1, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "[4, 3, 3, 1, 1, 1, 3, 4, 1, 2]\n",
      "[1, 1, 1, 1, 1, 0, 1, 0, 1, 0]\n",
      "[5, 4, 4, 4, 4, 1, 5, 1, 4, 1]\n",
      "[1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[5, 4, 3, 3, 1, 3, 1, 1, 3, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'map': 0.491984126984127,\n",
       " 'ndcg': 0.8054725683587982,\n",
       " 'map_scores': [0.4714285714285714, 1.0, 0.125, 0.6634920634920635, 0.2],\n",
       " 'ndcg_scores': [0.7519161237423574,\n",
       "  0.9885419998064646,\n",
       "  0.6863756975224844,\n",
       "  0.7526720307263396,\n",
       "  0.8478569899963447]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = run_relevance_tests(\"data/test.csv\", ranker1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8054725683587982\n",
      "0.10502486382314746\n",
      "0.6863756975224844\n",
      "0.9885419998064646\n"
     ]
    }
   ],
   "source": [
    "for func in [np.mean, np.std, np.min, np.max]:\n",
    "    print(func(a['ndcg_scores']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 1038.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 1, 1, 1, 0, 1, 0]\n",
      "[5, 3, 2, 1, 4, 4, 5, 1, 4, 3]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 4]\n",
      "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "[4, 2, 3, 3, 1, 4, 1, 1, 1, 3]\n",
      "[1, 1, 1, 1, 1, 0, 1, 0, 0, 1]\n",
      "[5, 4, 4, 4, 4, 1, 5, 1, 1, 4]\n",
      "[1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[5, 4, 1, 3, 3, 3, 1, 3, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'map': 0.4583492063492064,\n",
       " 'ndcg': 0.7850475744081123,\n",
       " 'map_scores': [0.3026984126984127,\n",
       "  1.0,\n",
       "  0.13333333333333333,\n",
       "  0.6557142857142857,\n",
       "  0.2],\n",
       " 'ndcg_scores': [0.683629066933712,\n",
       "  0.9885419998064646,\n",
       "  0.6736511294142714,\n",
       "  0.7509841338979839,\n",
       "  0.8284315419881301]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for qid in ranker:\n",
    "#     ranker[qid] = [movie_df[movie_df.title == x].id.values[0] for x in ranker[qid]]\n",
    "\n",
    "run_relevance_tests(\"data/test.csv\", ranker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si650",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
